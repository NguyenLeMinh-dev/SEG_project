import pandas as pd
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
import time
import re

# ==============================================================================
# SECTION 1: CONSTANTS AND CONFIGURATION
# ==============================================================================

# --- Input/Output Files ---
INPUT_CSV = "foody_cantho.csv"
OUTPUT_CSV = "foody_cantho_with_tags.csv"
NUM_TO_TEST = None # Set to None to run all rows: `NUM_TO_TEST = None`

# --- Culinary Dictionary ---
# This dictionary is the "brain" that helps identify meaningful tags.

# General categories from the website's filters
FOOD_CATEGORIES = [
    "Sang tr·ªçng", "Buffet", "Nh√† h√†ng", "ƒÇn v·∫∑t/v·ªâa h√®", "ƒÇn chay", 
    "Caf√©/Dessert", "Qu√°n ƒÉn", "Bar/Pub", "Qu√°n nh·∫≠u", "Beer club", 
    "Ti·ªám b√°nh", "Ti·ªác t·∫≠n n∆°i", "Shop Online", "Giao c∆°m vƒÉn ph√≤ng", "Khu ·∫®m Th·ª±c"
]

# Cuisine types from the website's filters
CUISINE_TYPES = [
    "M√≥n B·∫Øc", "M√≥n Trung Hoa", "M√≥n Mi·ªÅn Trung", "M√≥n Mi·ªÅn Nam", "M√≥n ·∫§n ƒê·ªô",
    "M√≥n Th√°i", "√ù", "Ph√°p", "ƒê·ª©c", "M√≥n Nh·∫≠t", "M√≥n H√†n", "Th·ª•y sƒ©", "Singapore", 
    "M·ªπ", "ƒê√†i Loan", "B√°nh Pizza", "ƒê·∫∑c s·∫£n v√πng"
]

# An expanded list of common Vietnamese dishes and keywords to improve recognition
COMMON_DISHES_KEYWORDS = [
    # Main dishes & Noodles
    "b√∫n", "ph·ªü", "c∆°m", "m√¨", "l·∫©u", "b√°nh m√¨", "x√¥i", "ch√°o", "h·ªß ti·∫øu", "mi·∫øn", 
    "b√∫n ri√™u", "b√∫n m·∫Øm", "b√∫n th·ªãt n∆∞·ªõng", "m√¨ qu·∫£ng", "cao l·∫ßu", "b√∫n b√≤ hu·∫ø", 
    "b√∫n b√≤", "b√∫n ch·∫£", "b√∫n ƒë·∫≠u", "c∆°m t·∫•m", "c∆°m rang", "c∆°m g√†", "m√¨ cay",
    # Various types of cakes
    "b√°nh x√®o", "b√°nh kh·ªçt", "b√°nh canh", "b√°nh tr√°ng", "b√°nh cu·ªën", "b√°nh b√®o", 
    "b√°nh b·ªôt l·ªçc", "b√°nh ng·ªçt", "b√°nh bao", "b√°nh flan", "b√°nh gi√≤", "b√°nh p√≠a",
    # Snacks & Appetizers
    "ƒÉn v·∫∑t", "g·ªèi cu·ªën", "nem n∆∞·ªõng", "nem chua r√°n", "ph√° l·∫•u", "tr·ª©ng v·ªãt l·ªôn", 
    "b·ªôt chi√™n", "g·ªèi", "s√∫p", "salad", "khoai t√¢y chi√™n", "x√∫c x√≠ch", "xi√™n que",
    "h√° c·∫£o", "s·ªßi c·∫£o", "ch·∫£ gi√≤", "ch·∫°o t√¥m", "g√† gi√≤n", "g√† r√°n", "m√¨ √Ω", "spaghetti",
    
    # Main ingredients
    "g√†", "v·ªãt", "b√≤", "heo", "c√°", "t√¥m", "cua", "gh·∫π", "h·∫£i s·∫£n", "·ªëc", "·∫øch", 
    "tr·ª©ng", "nem", "ch·∫£", "x√° x√≠u", "s∆∞·ªùn", "gi√≤", "pate", "ph√¥ mai",
    # Desserts & Drinks
    "ch√®", "tr√† s·ªØa", "c√† ph√™", "cafe", "sinh t·ªë", "n∆∞·ªõc √©p", "kem", "s·ªØa chua", 
    "t√†u h·ªß", "s√¢m b·ªï l∆∞·ª£ng", "rau m√°", "n∆∞·ªõc m√≠a", "tr√† ƒë√†o", "tr√† chanh", "matcha",
    # Styles & Cooking methods
    "chay", "dinh d∆∞·ª°ng", "quay", "chi√™n", "x√†o", "n∆∞·ªõng", "h·∫•p", "lu·ªôc", "th·∫≠p c·∫©m", 
    "ƒë·∫∑c bi·ªát", "b√¨nh d√¢n", "nh·∫≠u", "m·∫Øm t√¥m", "sushi", "pizza", "bbq", "steak"
]

# ==============================================================================
# SECTION 2: HELPER FUNCTIONS
# ==============================================================================

def build_tag_dictionary(lists_of_tags):
    """
    Creates a comprehensive set of valid, standardized tags from multiple lists.
    This set will be used as our dictionary for matching.
    """
    valid_tags = set()
    for tag_list in lists_of_tags:
        for item in tag_list:
            # Split items like "Caf√©/Dessert" into "Caf√©" and "Dessert"
            parts = re.split(r'[/()]', item)
            for part in parts:
                part = part.strip().lower()
                if part:
                    valid_tags.add(part)
    return valid_tags

def extract_meaningful_tags(text, dictionary):
    """
    Scans a block of text and extracts phrases (of 1, 2, or 3 words)
    that exist in our culinary dictionary.
    """
    found_tags = set()
    # Split text more robustly (by space, comma, hyphen, etc.)
    words = [word for word in re.split(r'[\s,-/&]+', text.lower()) if word]
    
    # Scan for 3-word, then 2-word, then 1-word phrases to prioritize longer, more specific tags
    for n in (3, 2, 1):
        for i in range(len(words) - n + 1):
            phrase = " ".join(words[i:i+n])
            if phrase in dictionary:
                found_tags.add(phrase)
    return found_tags

def scrape_all_tags(session, url, dictionary):
    """
    Performs the 3-step strategy to comprehensively gather tags for a given URL.
    1. Harvest: Get existing tags from the page.
    2. Infer: Extract keywords from the restaurant's name.
    3. Discover: Find keywords from the menu.
    """
    try:
        response = session.get(url, timeout=10)
        if response.status_code != 200: return ""
        soup = BeautifulSoup(response.text, 'html.parser')
        
        full_text_to_analyze = ""

        # Step 1: Harvest existing tags
        category_container = soup.select_one(".main-info-title .category")
        if category_container:
            full_text_to_analyze += " " + category_container.get_text(" ", strip=True)

        # Step 2: Infer from the restaurant name
        name_element = soup.select_one("h1[itemprop='name']")
        if name_element:
            full_text_to_analyze += " " + name_element.get_text(strip=True)

        # Step 3: Discover from the menu (up to 10 items)
        menu_items = soup.select(".delivery-dishes-group .delivery-dishes-item .title-name")[:10]
        for item in menu_items:
            full_text_to_analyze += " " + item.get_text(strip=True)
            
        # Final step: Match all collected text against our dictionary
        final_tags = extract_meaningful_tags(full_text_to_analyze, dictionary)
        
        # Capitalize and sort for clean output
        capitalized_tags = [tag.capitalize() for tag in final_tags]
        return ", ".join(sorted(list(set(capitalized_tags))))
        
    except Exception:
        return ""

# ==============================================================================
# SECTION 3: MAIN EXECUTION
# ==============================================================================

def main():
    """
    Main function to run the entire tag patching process.
    """
    # Build the master dictionary of tags
    valid_tags_dictionary = build_tag_dictionary([FOOD_CATEGORIES, CUISINE_TYPES, COMMON_DISHES_KEYWORDS])
    print(f"üìñ ƒê√£ x√¢y d·ª±ng t·ª´ ƒëi·ªÉn ho√†n ch·ªânh v·ªõi {len(valid_tags_dictionary)} tag h·ª£p l·ªá.")

    # --- Read the source CSV file ---
    try:
        df = pd.read_csv(INPUT_CSV)
        print(f"üìÇ ƒê√£ ƒë·ªçc {len(df)} d√≤ng t·ª´ '{INPUT_CSV}'.")
    except FileNotFoundError:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_CSV}'. Vui l√≤ng ch·∫°y script c√†o d·ªØ li·ªáu ch√≠nh tr∆∞·ªõc.")
        return

    # --- Prepare for scraping ---
    df_to_process = df.head(NUM_TO_TEST).copy() if NUM_TO_TEST is not None else df.copy()
    if NUM_TO_TEST is not None:
        print(f"üî¨ Ch·∫ø ƒë·ªô TEST: Ch·ªâ x·ª≠ l√Ω {len(df_to_process)} qu√°n ƒÉn ƒë·∫ßu ti√™n.")

    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    })

    if 'tags' not in df.columns:
        df['tags'] = ''

    # --- Start the scraping loop ---
    print(f"\nüè∑Ô∏è  B·∫Øt ƒë·∫ßu qu√° tr√¨nh 'v√°' tags cho {len(df_to_process)} qu√°n ƒÉn...")
    for index, row in tqdm(df_to_process.iterrows(), total=df_to_process.shape[0], desc="Updating tags"):
        url = row['url']
        tags = scrape_all_tags(session, url, valid_tags_dictionary)
        
        # Update the tag directly in the original DataFrame
        df.loc[index, 'tags'] = tags
        time.sleep(0.1) # Small delay to be polite to the server

    # --- Save the enriched data ---
    df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
    print(f"\nüéâ HO√ÄN T·∫§T! ƒê√£ l∆∞u d·ªØ li·ªáu ƒë∆∞·ª£c l√†m gi√†u v√†o file: '{OUTPUT_CSV}'")
    if NUM_TO_TEST is not None:
        print(f"L∆∞u √Ω: Ch·ªâ {NUM_TO_TEST} d√≤ng ƒë·∫ßu ti√™n ƒë∆∞·ª£c c·∫≠p nh·∫≠t tags m·ªõi.")

if __name__ == "__main__":
    main()

